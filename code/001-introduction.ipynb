{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: what is image processing?\n",
    "(teaching: 15 minutes, exercises: 5 minutes)\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- What is image processing and how is it useful in neuroimaging?\n",
    "- How are images represented in scientific computing?\n",
    "\n",
    "### Objectives:\n",
    "- Explain the role of image processing in neuroimaging\n",
    "- Identify image data, and distinguish it from other data (e.g., tabular, time-series, etc.)\n",
    "- Extract image data from neuroimaging file formats with nibabel\n",
    "- Slice and stride through data arrays with numpy indexing operations\n",
    "- Visualize image data with Matplotlib\n",
    "\n",
    "### Key points:\n",
    "\n",
    "- Image processing operations are a central part of neuroimaging.\n",
    "- Images are homogenous arrays, where spatial relationships are important\n",
    "- Many different operations can be performed on images, and processing pipelines can be build combining them\n",
    "- Images can be efficiently and usefully represented as arrays\n",
    "- Arrays can be manipulated with numpy operations, and visualized using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing is central to neuroimaging\n",
    "\n",
    "Image processing is a large and very general set of tools that are used across a\n",
    "variety of research disciplines to analyze image data. Naturally, image\n",
    "processing algorithms are fundamental to neuroimaging, because a lot (if not\n",
    "all) the data that we analyze in neuroimaging is image data.\n",
    "\n",
    "What is image data? How is it different from other data, such as time-series,\n",
    "or tabular data?\n",
    "\n",
    "For our purposes: image data is defined as multi-dimensional homogenous data in\n",
    "which *spatial relationships matter*. That is, neighboring pixels are treated\n",
    "differently than pixels from disparate parts of the array. Spatial contiguity is\n",
    "meaningful. Usually, image data will have 2 or 3 dimensions, corresponding to\n",
    "the 3 spatial dimensions or 2D projection: either from a specific view-point\n",
    "(think photographs) or through a 3D object (think slice). But it is possible to\n",
    "use image processing algorithms in cases in which there are more dimensions, and\n",
    "where the dimensions do not correspond to the spatial dimensions (does anyone\n",
    "know a good example of this?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## What is a good example of pseudo-image data?\n",
    ">\n",
    "> - In radio-astronomy, Fourier spectra are analyzed using image-processing\n",
    ">   methods\n",
    "> - In a project recently undertaken in the \n",
    "> [University of Washington eScience Institute Data Science Incubator Program](http://escience.washington.edu/get-involved/incubator-programs/winter-2016/),\n",
    "> Siva Kasinathan used image-processing algorithms to characterize and reassemble sequences from human chromosome centromeres.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that these categories are also not mutually exclusive. For example,\n",
    "> functional MRI data is image data, but is also time-series data at the same\n",
    "> time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some common image processing operations\n",
    "\n",
    "There are many different kinds of image processing operations. Here are a few common operations:\n",
    "\n",
    "- Filtering\n",
    "  - Detrending\n",
    "  - Denoising\n",
    "  - Smoothing\n",
    "- Segmentation\n",
    "- Feature detection\n",
    "- Texture analysis\n",
    "- Statistical characterization\n",
    "- Classification\n",
    "- Registration\n",
    "- Combination (e.g. 'stitching')\n",
    "\n",
    "\n",
    "### Images can be represented in arrays\n",
    "\n",
    "Because of their nature (homogenous/spatial dimensions matter) data lend\n",
    "themselves easily to a representation as arrays. Let's demonstrate this with\n",
    "some human neuroimaging data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nibabel: accessing a cacophony of neuroimaging file formats\n",
    "\n",
    "One of the challenges of data science in neuroimaging (and in other\n",
    "scientific fields) is the range of different file formats that are used to\n",
    "store data. Often these files will be opaque to a naive user, because the data\n",
    "is stored in a binary format, that cannot be read without knowledge of the\n",
    "organization of the data on disks.\n",
    "\n",
    "The `nibabel` library alleviates these difficulty through a careful\n",
    "implemntation of a wider range of different neuroimaging file-formats.\n",
    "Wherever possible, the library presents a common interface to these different\n",
    "file formats, making it particularly easy to write code that will work on\n",
    "data stored in these different formats.\n",
    "\n",
    "To install it, you can use the following command-line call:\n",
    "\n",
    "     pip install nibabel\n",
    "     \n",
    "## Dipy: diffusion MRI and computational neuroimaging\n",
    "\n",
    "[`Dipy`](http://dipy.org) stands for \"diffusion MRI in Python\", but \n",
    "it is a library devoted to diffusion MRI, as well as other applications\n",
    "in computational neuroimaging. Later in this lesson, we will use Dipy \n",
    "for its capabilities in image registration. For now, we will use the \n",
    "library to access openly available human neuroimaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dipy.data as dpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remote, local = dpd.fetch_stanford_t1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(remote)\n",
    "print(local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`remote` is the URL from which the data was read (and a cryptographic hash used to validate the data)\n",
    "\n",
    "`local` is where the data is stored on your machine\n",
    "\n",
    "IPython knows how to make sense of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls $local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a compressed NIfTI file (`nii.gz` extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the file we want is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "t1_file = op.join(local, 't1.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nibabel` API for reading data from file has two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "T1w_img = nib.load(t1_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `nibabel` loads the data \"lazily\", the data hasn't been read into memory\n",
    "yet, only some basic metadata stored in the file header. To access the data, we\n",
    "need to explicitly call the `get_data` method of the image object that we\n",
    "currently have in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T1w_data = T1w_img.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a `numpy` array. We can verify that by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(T1w_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some basic properties of this array by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(T1w_data.shape)\n",
    "print(T1w_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the data that was stored in the file using `Matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.matshow(T1w_data[:, :, T1w_data.shape[-1]//2], cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exercise: The nibabel header\n",
    ">\n",
    "> Explore the 'T1w_img' object. How would you extract information about the\n",
    "> parameters used to collect data? What information is missing?\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Solution: The nibabel header\n",
    ">  \n",
    "> Information about the acquisition can be accessed using the image header:\n",
    ">\n",
    ">     hdr = T1w_img.get_header()\n",
    ">\n",
    "> For example:\n",
    ">\n",
    ">     affine = hdr.get_zooms()\n",
    ">\n",
    "> will usually provide the dimensions of the voxel (how do we know the units?)\n",
    ">\n",
    "> Some information might be missing from the file header (or not make sense).\n",
    "> For example, try running:\n",
    ">\n",
    ">     hdr.get_n_slices()\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Affine transforms\n",
    ">\n",
    "> The nibabel image header also contains the affine transformation between the\n",
    "> image and a standard space (usually the scanner iso-center in mm). For more\n",
    "> information on how and why this information is used, you might want to refer\n",
    "> to [this excellent tutorial in the nibabel documentation](http://nipy.org/nibabel/coordinate_systems.html).\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
